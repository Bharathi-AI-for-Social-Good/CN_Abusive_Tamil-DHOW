{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "annotated_by": "GPT-5 Thinking",
    "annotation_timestamp_utc": "2025-08-16T08:01:42.621188Z"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install all the required libraries for implementing retrieval-augmented generation (RAG), large language model (LLM) integrations, embedding-based similarity search, and dataset handling, ensuring a unified environment for counter-narrative generation experiments."
      ],
      "metadata": {
        "id": "uz1AAZ3s029j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpbYCzw802IP"
      },
      "outputs": [],
      "source": [
        "!pip install -U langgraph langchain_openai google-generativeai langchain-community langchain-google-genai langchain-anthropic anthropic sentence-transformers faiss-cpu datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcdbr_uM5zHg"
      },
      "source": [
        "Import all the required API token keys for all the models used\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '<OPENAI_API_KEY>'\n",
        "os.environ['HF_TOKEN'] = '<HF_TOKEN>'\n",
        "os.environ['GOOGLE_API_KEY'] = '<GOOGLE_API_KEY>'\n",
        "os.environ['ANTHROPIC_API_KEY'] = '<ANTHROPIC_API_KEY>'"
      ],
      "metadata": {
        "id": "0-Kzv0Q81B7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "  \"\"\"\n",
        "  Represents the state of an agent in the conversation.\n",
        "  \"\"\"\n",
        "\n",
        "  keys: Dict[str, any]"
      ],
      "metadata": {
        "id": "iYWj3enT1Nu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First step is to generate contextual queries based on the Hate speech"
      ],
      "metadata": {
        "id": "djwqIki_1aHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "def generate_queries(state):\n",
        "  from langchain_core.documents import Document\n",
        "\n",
        "  state_dict = state[\"keys\"]\n",
        "  hate_speech = state_dict[\"hate_speech\"]\n",
        "\n",
        "  template = \"\"\"\n",
        "  பின்வரும் தமிழில் உள்ள வெறுப்புப் பேச்சு கூறுக்கு எதிராக ஒரு தரமான எதிர் பேச்சை உருவாக்க வேண்டியுள்ளது:\n",
        "\n",
        "\"{hatespeech}\"\n",
        "\n",
        "இந்தக் குறிப்பிட்ட வெறுப்புப் பேச்சுக்கு பொருந்தக்கூடிய எதிர் பேச்சை உருவாக்க பயன்படுத்தத்தக்க 3 ஆய்வுக் கேள்விகளை உருவாக்கவும்.\n",
        "\n",
        "- கேள்விகள் தவிர வேறு உரை (முன்னுரை, விளக்கம்) இட வேண்டாம்.\n",
        "- ஒவ்வொரு கேள்வியும் தனித்தனி வரியில் இடம்பெற வேண்டும்.\n",
        "- அனைத்து கேள்விகளும் தமிழில் மட்டும் இருக்க வேண்டும்.\n",
        "- ஒவ்வொரு கேள்வியும் 1., 2., 3. என்ற எண்ணுக்குறிப்புடன் தொடங்க வேண்டும்.\n",
        "  \"\"\"\n",
        "\n",
        "  query_template = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "  chain = query_template | llm | StrOutputParser()\n",
        "\n",
        "  output = chain.invoke({\"hatespeech\": hate_speech})\n",
        "  queries = re.findall(r\"\\d+\\.\\s*(.*)\", output.strip())\n",
        "\n",
        "  return {\"keys\": {\"hate_speech\": hate_speech, \"queries\": queries}}"
      ],
      "metadata": {
        "id": "IBjEs7hv1aop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68PgqqWA5zHj"
      },
      "source": [
        "Loads the HinduTamil-News-Articles-Dataset to get the fact based counter narratives\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dataset = load_dataset(\"Shwetasss/HinduTamil-News-Articles-Dataset\", split=\"train\")\n",
        "embedder = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "corpus = [doc['Text'] for doc in dataset]\n",
        "corpus_embeddings = embedder.encode(corpus, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "dimension = corpus_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(corpus_embeddings)\n",
        "\n",
        "id_map = {i: doc for i, doc in enumerate(dataset)}"
      ],
      "metadata": {
        "id": "pePLLixI1fbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2blZUbv5zHj"
      },
      "source": [
        "\n",
        "*   Retrieves the top 2 relevant documents based on the hate speech and contextual queries\n",
        "*   Summarizes the documents to 2 - 3 sentences\n",
        "*   Filters relevant documents based on hate speech and the query\n",
        "*   Generates three candidate counter narratives\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "#from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "def retrieve_documents_tamil(state, top_k=2):\n",
        "    state_dict = state[\"keys\"]\n",
        "    hate_speech = state_dict[\"hate_speech\"]\n",
        "    queries = state_dict[\"queries\"]\n",
        "\n",
        "    query_document_pairs = []\n",
        "    query_embeddings = embedder.encode(queries, convert_to_numpy=True)\n",
        "\n",
        "    for query, query_embedding in zip(queries, query_embeddings):\n",
        "        distances, indices = index.search(np.array([query_embedding]), top_k)\n",
        "        for idx in indices[0]:\n",
        "            document = id_map[idx]\n",
        "            #print(f\"document is : {document}\")\n",
        "            query_document_pairs.append({\n",
        "                \"query\": query,\n",
        "                \"document\": {\n",
        "                    \"title\": document['Text']\n",
        "                }\n",
        "            })\n",
        "    #print(query_document_pairs)\n",
        "    return {\"keys\": {\"hate_speech\": hate_speech, \"queries\": queries, \"query_document_pairs\": query_document_pairs}}\n",
        "\n",
        "def summarize_documents(state):\n",
        "  state_dict = state[\"keys\"]\n",
        "  hate_speech = state_dict[\"hate_speech\"]\n",
        "  queries = state_dict[\"queries\"]\n",
        "  query_document_pairs = state_dict[\"query_document_pairs\"]\n",
        "\n",
        "  summary_prompt = \"\"\"\n",
        "    இந்த ஆவணத்தை 2 அல்லது 3 வசனங்களில் சுருக்கவும். சுருக்கம், கீழ்க்கண்ட கேள்விக்கு பதிலளிக்க வேண்டும் மற்றும் வெறுப்புப் பேச்சுக்கு எதிரான தகவல்களை உள்ளடக்கியதாக இருக்க வேண்டும். தொடர்புடைய புள்ளிவிவரங்கள் மற்றும் தகவல் மூலங்களை விட்டுவிடாமல் சேர்க்கவும்.\n",
        "\n",
        "    கேள்வி: {query}\n",
        "\n",
        "    வெறுப்புப் பேச்சு: {hs}\n",
        "\n",
        "    ஆவணம்: {document}\n",
        "\n",
        "  \"\"\"\n",
        "  prompt = ChatPromptTemplate.from_template(summary_prompt)\n",
        "\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "  query_summarized_document_pairs = []\n",
        "\n",
        "  for query_document_pair in query_document_pairs:\n",
        "    document_summary = chain.invoke({\"query\":query_document_pair[\"query\"],\"document\":query_document_pair[\"document\"], \"hs\":hate_speech})\n",
        "    query_summarized_document_pairs.append({\"query\": query_document_pair[\"query\"], \"document\": document_summary})\n",
        "\n",
        "  #print(f\"query_summarized_document_pairs : {query_summarized_document_pairs}\")\n",
        "\n",
        "  return {\"keys\": {\"hate_speech\": hate_speech, \"queries\": queries, \"query_document_pairs\": query_document_pairs, \"query_summarized_document_pairs\": query_summarized_document_pairs}}\n",
        "\n",
        "def grade_documents(state):\n",
        "  from langchain_core.documents import Document\n",
        "  state_dict = state[\"keys\"]\n",
        "  hate_speech = state_dict[\"hate_speech\"]\n",
        "  queries = state_dict[\"queries\"]\n",
        "  query_document_pairs = state_dict[\"query_document_pairs\"]\n",
        "  query_summarized_document_pairs = state_dict[\"query_summarized_document_pairs\"]\n",
        "\n",
        "  #print(f\"Summarized document pairs:  {query_summarized_document_pairs}\")\n",
        "\n",
        "  grade_prompt = \"\"\"\n",
        "  நீங்கள் வெறுப்புப் பேச்சுக்கு எதிராக ஒரு எதிர்பேச்சு உருவாக்க பயன்படும் பதிவுக்கான தொடர்பை மதிப்பீடு செய்யும் ஒரு மதிப்பீட்டாளர்.\n",
        "\n",
        "  பின்வரும் தகவல்களை கவனமாக படிக்கவும்:\n",
        "\n",
        "  - வெறுப்புப் பேச்சு: {hs}\n",
        "\n",
        "  - தேடலுக்காக உருவாக்கப்பட்ட கேள்வி: {question}\n",
        "\n",
        "  - தேடப்பட்ட ஆவணம்: {document}\n",
        "\n",
        "  இந்த ஆவணம், மேலே கொடுக்கப்பட்ட வெறுப்புப் பேச்சுக்கு எதிராக ஒரு அர்த்தமுள்ள எதிர்பேச்சு உருவாக்குவதற்கு பயன்படுமா என்பதை மதிப்பீடு செய்ய வேண்டும்.\n",
        "\n",
        "  **தரவரிசை அளவுகள்:**\n",
        "\n",
        "  - **1** — ஆவணத்தில் உள்ள தகவல்கள், எதிர்பேச்சு உருவாக்குவதற்கு உதவக்கூடியவையாக இருந்தால்.\n",
        "\n",
        "  - **0** — ஆவணம் வெறுப்புப் பேச்சுடன் ஏற்கெனவே ஒத்துப் போனால் அல்லது எதிர்பேச்சு உருவாக்குவதற்கு பயன்படாததெனத் தோன்றினால்.\n",
        "\n",
        "  உங்கள் பதிலை எந்தவித விளக்கமும் இல்லாமல், வெறும் ஒரு இலக்கமாக (0 அல்லது 1) மட்டும் பதியவும்.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  prompt_template = ChatPromptTemplate.from_template(grade_prompt)\n",
        "\n",
        "  filtered_query_document_pairs = []\n",
        "\n",
        "  for query_summarized_document_pair in query_summarized_document_pairs:\n",
        "      query = query_summarized_document_pair[\"query\"]\n",
        "      document = query_summarized_document_pair[\"document\"]\n",
        "\n",
        "      chain = prompt_template | llm | StrOutputParser()\n",
        "      score = chain.invoke({\n",
        "          \"document\": document,\n",
        "          \"hs\": hate_speech,\n",
        "          \"question\": query\n",
        "      }).strip()\n",
        "\n",
        "      if score.lower() == \"1\":\n",
        "          #print(\"Document is relevant!\")\n",
        "          filtered_query_document_pairs.append(query_summarized_document_pair)\n",
        "      else:\n",
        "          print(\"Document is irrelevant!\")\n",
        "\n",
        "  return {\n",
        "        \"keys\": {\n",
        "            \"hate_speech\": hate_speech,\n",
        "            \"queries\": queries,\n",
        "            \"query_document_pairs\": query_document_pairs,\n",
        "            \"query_summarized_document_pairs\": query_summarized_document_pairs,\n",
        "            \"filtered_query_document_pairs\": filtered_query_document_pairs\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_counterspeech(state):\n",
        "  from langchain_core.documents import Document\n",
        "\n",
        "  state_dict = state[\"keys\"]\n",
        "  hate_speech = state_dict[\"hate_speech\"]\n",
        "  queries = state_dict[\"queries\"]\n",
        "  query_document_pairs = state_dict[\"query_document_pairs\"]\n",
        "  query_summarized_document_pairs = state_dict[\"query_summarized_document_pairs\"]\n",
        "  filtered_query_document_pairs = state_dict[\"filtered_query_document_pairs\"]\n",
        "\n",
        "  cn_prompt = \"\"\"\n",
        "  பின்வரும் வெறுப்புப் பேச்சுக்கு எதிராக தரமான மூன்று எதிர் பேச்சுகளை (Counter Speech) உருவாக்கவும். கீழே வழங்கப்படும் தகவல்கள் பல்வேறு ஆதாரங்களிலிருந்து பெறப்பட்டுள்ளன. இத்தகவல்களை உங்கள் பதில்களில் உள்ளடக்கவும் மற்றும் தேவையான இடங்களில் மேற்கோள்கள் (sources) குறிப்பிடவும்.\n",
        "\n",
        "  தகவல் சார்ந்த உள்ளடக்கம் : {context}\n",
        "\n",
        "  வெறுப்புப் பேச்சு : {hatespeech}\n",
        "\n",
        "  உங்கள் பதிலில், ஒவ்வொரு எதிர் பேச்சும் தனித்தனி வரியில் 1., 2., 3. என தொடங்க வேண்டும். ஒவ்வொன்றும் அதிகபட்சம் இரண்டு வரிகளாக மட்டுப்படுத்தப்பட வேண்டும்.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_template(cn_prompt)\n",
        "\n",
        "  context = \"\\n\\n\".join([doc['document'] for doc in filtered_query_document_pairs])\n",
        "\n",
        "  llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "  #llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "  #llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", temperature=0)\n",
        "\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  gpt_counter_narratives = chain.invoke({\"context\":context,\"hatespeech\":hate_speech})\n",
        "  #print(f\"Counter Narratives are : {gpt_counter_narratives}\")\n",
        "\n",
        "  return {\"keys\":\n",
        "            {\"hate_speech\": hate_speech,\n",
        "            \"queries\": queries,\n",
        "            \"query_document_pairs\": query_document_pairs,\n",
        "            \"filtered_query_document_pairs\": filtered_query_document_pairs,\n",
        "            \"query_summarized_document_pairs\": query_summarized_document_pairs,\n",
        "            \"gpt_4o_counterspeech\": gpt_counter_narratives,\n",
        "            }}\n",
        "\n"
      ],
      "metadata": {
        "id": "fSYfdj0K1h0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slraypTe5zHk"
      },
      "source": [
        "Generates the best Counter narrative based on the above three candidate counter narratives and uses the HITL approach V5 dataset to get the relevant examples for a given hate speech\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
        "\n",
        "def retrieve_top_k_examples(input_text, ref_texts, ref_cns, k=5):\n",
        "    \"\"\"\n",
        "    Retrieves top-k most similar hate speech examples using cosine similarity.\n",
        "    \"\"\"\n",
        "    query_embedding = model.encode([input_text], convert_to_tensor=True)\n",
        "    similarities = util.cos_sim(query_embedding, ref_texts)[0]\n",
        "    top_indices = similarities.topk(k=k).indices.tolist()\n",
        "\n",
        "    top_examples = [(ref_texts[i], ref_cns[i]) for i in top_indices]\n",
        "    return top_examples\n",
        "\n",
        "def generate_best_counterspeech(state):\n",
        "  from langchain_core.documents import Document\n",
        "\n",
        "  ### HITL V5 as KB\n",
        "  ref_df = pd.read_excel('tamil_hs_cn_v5.xlsx')\n",
        "  test_df = pd.read_excel('golden_hs_cn_test_set.xlsx')\n",
        "\n",
        "  ref_hs_list = ref_df['Hate speech'].fillna('').tolist()\n",
        "  ref_cn_list = ref_df['Counter Narrative from dataset'].fillna('').tolist()\n",
        "  ref_embeddings = model.encode(ref_hs_list, convert_to_tensor=True)\n",
        "\n",
        "\n",
        "  state_dict = state[\"keys\"]\n",
        "  hate_speech = state_dict[\"hate_speech\"]\n",
        "  queries = state_dict[\"queries\"]\n",
        "  query_document_pairs = state_dict[\"query_document_pairs\"]\n",
        "  query_summarized_document_pairs = state_dict[\"query_summarized_document_pairs\"]\n",
        "  filtered_query_document_pairs = state_dict[\"filtered_query_document_pairs\"]\n",
        "  counter_narratives = state_dict[\"gpt_4o_counterspeech\"]\n",
        "\n",
        "  cn_prompt = \"\"\"\n",
        "  பின்வரும் வெறுப்புப் பேச்சுக்கு எதிராக, தகவல் மற்றும் உண்மைகளில் அடிப்படையிலான, ஒரு தரமான, தெளிவான மற்றும் சமூக பொறுப்புடன் கூடிய எதிர்பேச்சை உருவாக்கவும்.\n",
        "\n",
        "  கீழே வழங்கப்பட்டுள்ள மூன்று எதிர்பேச்சுகளும் தத்தமதாக சில சிறப்பம்சங்களை கொண்டுள்ளன. அவற்றில் சிறந்த கூறுகளை எடுத்துக்கொண்டு, ஒரு சுருக்கமான (அதிகபட்சம் 2 வரிகள்), உண்மை சார்ந்த மற்றும் உறுதியான எதிர்பேச்சை உருவாக்கவும். தேவையான இடங்களில் ஆதாரங்களை (sources) குறிப்பிடவும்.\n",
        "\n",
        "- வெறுப்புப் பேச்சு:   {hatespeech}\n",
        "\n",
        "- தகவல் சார்ந்த உள்ளடக்கம்:   {context}\n",
        "\n",
        "- மூன்று எதிர்பேச்சுகள்:   {counter_narratives}\n",
        "\n",
        "- உதாரணங்கள்:\n",
        "  \"\"\"\n",
        "\n",
        "  top_k = retrieve_top_k_examples(hate_speech, ref_hs_list, ref_cn_list, k=5)\n",
        "  #print(f\"Examples of hs {hate_speech} are {top_k}\")\n",
        "\n",
        "  for hs, cn in top_k:\n",
        "      cn_prompt += f\"வெறுப்புப் பேச்சு: {hs}\\nஎதிர்வினை: {cn}\\n\\n\"\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_template(cn_prompt)\n",
        "\n",
        "  context = \"\\n\\n\".join([doc['document'] for doc in filtered_query_document_pairs])\n",
        "\n",
        "  llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "  #llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "  #llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", temperature=0)\n",
        "\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  counter_narrative = chain.invoke({\"context\":context,\"hatespeech\":hate_speech, \"counter_narratives\": counter_narratives})\n",
        "  print(f\"Final Counter Narrative is : {counter_narrative}\")\n",
        "\n",
        "  return {\"keys\":\n",
        "            {\"hate_speech\": hate_speech,\n",
        "            \"queries\": queries,\n",
        "            \"query_document_pairs\": query_document_pairs,\n",
        "            \"filtered_query_document_pairs\": filtered_query_document_pairs,\n",
        "            \"query_summarized_document_pairs\": query_summarized_document_pairs,\n",
        "            \"gpt_4o_counterspeech\": counter_narratives,\n",
        "            \"final_counter_narrative\": counter_narrative,\n",
        "            }}"
      ],
      "metadata": {
        "id": "qseuU5hA2RiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfiKK2tX5zHk"
      },
      "source": [
        "Defines and compiles a state-based counter-narrative generation pipeline using LangGraph. The pipeline is structured as a directed graph where each node represents a modular task in the generation process. The flow begins with query generation, followed by document retrieval in Tamil, document summarization, and document grading to filter the most relevant evidence. The graded content is then used to generate multiple counter-speech candidates, from which the best counter-speech is selected.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "pipeline = StateGraph(GraphState)\n",
        "\n",
        "pipeline.add_node(\"generate_queries\", generate_queries)\n",
        "pipeline.add_node(\"retrieve_documents_tamil\", retrieve_documents_tamil)\n",
        "pipeline.add_node(\"summarize_documents\", summarize_documents)\n",
        "pipeline.add_node(\"grade_documents\", grade_documents)\n",
        "pipeline.add_node(\"generate_counterspeech\", generate_counterspeech)\n",
        "pipeline.add_node(\"generate_best_counterspeech\", generate_best_counterspeech)\n",
        "\n",
        "pipeline.set_entry_point(\"generate_queries\")\n",
        "pipeline.add_edge(\"generate_queries\", \"retrieve_documents_tamil\")\n",
        "pipeline.add_edge(\"retrieve_documents_tamil\", \"summarize_documents\")\n",
        "pipeline.add_edge(\"summarize_documents\", \"grade_documents\")\n",
        "pipeline.add_edge(\"grade_documents\", \"generate_counterspeech\")\n",
        "pipeline.add_edge(\"generate_counterspeech\", \"generate_best_counterspeech\")\n",
        "\n",
        "app = pipeline.compile()"
      ],
      "metadata": {
        "id": "g5eEl6BC3rh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuzYAyOk5zHl"
      },
      "source": [
        "This code applies the counter-narrative generation pipeline to each hate speech instance in golden_hs_cn_test_set.xlsx. For every input, it extracts the best fact-based counter-narrative along with the supporting factual context from retrieved documents. The results are appended to a new dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"golden_hs_cn_test_set.xlsx\")\n",
        "\n",
        "ta_counter_narratives = []\n",
        "ta_context = []\n",
        "\n",
        "for hs_text in df['Hate speech']:\n",
        "  inputs = {\"keys\": {\"hate_speech\": hs_text}}\n",
        "\n",
        "  tamil_cn = \"\"\n",
        "\n",
        "  for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "\n",
        "      if key == \"generate_best_counterspeech\":\n",
        "        results = value[\"keys\"]\n",
        "        print(f\"results : {results}\")\n",
        "        tamil_cn = results.get(\"final_counter_narrative\")\n",
        "        print(f\"tamil_cn : {tamil_cn}\")\n",
        "        context = results.get(\"filtered_query_document_pairs\")\n",
        "\n",
        "  ta_counter_narratives.append(tamil_cn)\n",
        "  ta_context.append(context)\n",
        "\n",
        "\n",
        "df[\"fact_counter_narratives\"] = ta_counter_narratives\n",
        "df[\"fact_context\"] = ta_context\n",
        "\n",
        "df.to_excel(\"fact_counter_narratives.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "m8yvctoE3vKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero-Shot Prompting**"
      ],
      "metadata": {
        "id": "jU2yhHgX37Ur"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpm4ZGdQ5zHl"
      },
      "source": [
        "This approach uses the GPT-4o model to generate zero-shot counter-narratives for each hate speech sample in golden_hs_cn_test_set.xlsx. A structured Tamil prompt guides the model to produce short, respectful, and fact-based responses tailored to the hate speech category. The generated counter-narratives are stored in a new column and exported as zero_shot_cn_gpt4o.xlsx for further evaluation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "client = openai.OpenAI(api_key=\"\")\n",
        "\n",
        "df = pd.read_excel(\"golden_hs_cn_test_set.xlsx\")\n",
        "df = df.dropna(subset=['Hate speech'])\n",
        "\n",
        "df[\"Generated_CN_GPT4o\"] = \"\"\n",
        "\n",
        "def build_prompt(hs_text: str, category: str) -> str:\n",
        "    return f\"\"\"\n",
        "நீங்கள் ஒரு சமூக பொறுப்புள்ள மொழி உருவாக்கும் நுண்ணறிவு மாடலாக செயல்படுகிறீர்கள். கீழே கொடுக்கப்பட்டுள்ள '{category}' வகையைச் சேர்ந்த வெறுப்புப் பேச்சுக்கு (Hate Speech) ஒரு உண்மையியல் அடிப்படையிலான, மதிப்புமிக்க எதிர்பேச்சை (Counter Narrative) உருவாக்கவும்.\n",
        "\n",
        "தயவுசெய்து பின்வரும் வழிகாட்டுதல்களை பின்பற்றவும்:\n",
        "- வெறுப்பை வன்முறையற்ற முறையில் எதிர்த்து, சமூக ஒற்றுமையை வலியுறுத்த வேண்டும்.\n",
        "- உண்மைத் தரவுகள் அல்லது பொதுத் தகவல்களைக் கொண்டு ஆதரிக்கப்பட வேண்டும்.\n",
        "- அதிகபட்சம் இரண்டு வரிகளுக்குள் சுருக்கமாக இருக்க வேண்டும்.\n",
        "- யாரையும் நையப்புடை செய்யாமல், மதிப்போடு பதிலளிக்க வேண்டும்.\n",
        "\n",
        "வெறுப்புப் பேச்சு:\n",
        "\\\"{hs_text}\\\"\n",
        "\n",
        "உங்கள் எதிர்பேச்சு:\n",
        "\"\"\"\n",
        "\n",
        "# Loop through HS samples and generate CNs\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        prompt = build_prompt(row['Hate speech'], row['Category'])\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"நீங்கள் சமூக பொறுப்புடன் செயல்படும் உதவியாளராகும். வெறுப்புப் பேச்சுக்கு எதிராக உண்மைத் தரவுகளின் அடிப்படையில் மரியாதைமிக்க, உணர்வுபூர்வமான மற்றும் தகவலளிக்கும் பதில்களை, அதிகபட்சம் இரண்டு வரிகளில் உருவாக்க பயிற்சி பெற்றுள்ளீர்கள்.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=150,\n",
        "        )\n",
        "\n",
        "        generated_cn = response.choices[0].message.content.strip()\n",
        "        df.at[idx, \"Zero_Shot_CN_GPT4o\"] = generated_cn\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error at index {idx}: {e}\")\n",
        "        df.at[idx, \"Zero_Shot_CN_GPT4o\"] = \"ERROR\"\n",
        "\n",
        "df.to_excel(\"zero_shot_cn_gpt4o.xlsx\", index=False)\n"
      ],
      "metadata": {
        "id": "udBG6e4u4DTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Few-Shot Prompting**"
      ],
      "metadata": {
        "id": "t6_jimzL4Qj8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BWL8KKR5zHl"
      },
      "source": [
        "This approach generates few-shot counter-narratives for Tamil hate speech using GPT-4o, guided by a prompt that includes 10 example hate speech counter narrative pairs as demonstrations. The generated outputs are stored in a new column and saved to few_shot_10_cn_gpt4o.xlsx for further evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "client = openai.OpenAI(api_key=\"\")\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_excel(\"golden_hs_cn_test_set.xlsx\")\n",
        "df = df.dropna(subset=['Hate speech'])\n",
        "\n",
        "df[\"Generated_CN_GPT4o\"] = \"\"\n",
        "\n",
        "def build_prompt(hs_text: str, category: str) -> str:\n",
        "    return f\"\"\"\n",
        "நீங்கள் ஒரு சமூக பொறுப்புடன் செயல்படும் உதவியாளர். கீழே சில வெறுப்புப் பேச்சுகள் மற்றும் அவற்றுக்கான உண்மை மற்றும் மரியாதையுடன் அமைந்த எதிர்ப்புப் பேச்சுகள் (Counter Narratives) வழங்கப்பட்டுள்ளன. இந்த எடுத்துக்காட்டுகளின் அடிப்படையில், பின்வரும் புதிய வெறுப்புப் பேச்சுக்கு ஒரு சுருக்கமான (அதிகபட்சம் 2 வரிகள்), உண்மையைக் கொண்ட மற்றும் சமூக ஒற்றுமையை ஊக்குவிக்கும் எதிர் பேச்சை உருவாக்கவும்.\n",
        "\n",
        "உதாரணங்கள்:\n",
        "\n",
        "1.\n",
        "வெறுப்புப் பேச்சு: இது எங்க நாடு அனைவருக்கும் பிரித்தானியர் நாடு தான் பெண்களும் குடியேறிய சொல்லிகளும் பலம் பெற்றுவருவார்கள்\n",
        "எதிர் பேச்சு: அனைவரும் ஒன்றாக வாழும் இந்த நாட்டில் மதம், மொழி, வரலாறு எதுவாக இருந்தாலும், அனைவரும் சமபாதமாக இருக்க வேண்டும்.\n",
        "\n",
        "2.\n",
        "வெறுப்புப் பேச்சு: வெளிநாட்டு முஸ்லிம்கள் இங்கே வந்து எங்களுக்கு பயம் கொடுக்கிறார்கள், தலைமுறை வேண்டாம் சாதிக்கலாம்\n",
        "எதிர் பேச்சு: எல்லா சமூகங்களும் இங்கே சமமாக வாழக்கூடிய உரிமையுடையவர்கள்; பயத்தையும் வெறுப்பையும் இல்லாமல் ஒருமைப்பாட்டை வளர்க்க வேண்டியது நம் கடமை.\n",
        "\n",
        "3.\n",
        "வெறுப்புப் பேச்சு: அதே போல் பெண்களும்...... ஆண்கள் அதிகம் சம்பளம் வாங்க வேண்டும் என்ற எண்ணத்தை....கை விட வேண்டும்\n",
        "எதிர் பேச்சு: வேலைக்கான சம்பள வேறுபாடு சமூகத்தில் ஆழமான பாகுபாடை காட்டுகிறது. சமபள உரிமை அனைவருக்கும் இருக்க வேண்டும்.\n",
        "\n",
        "4.\n",
        "வெறுப்புப் பேச்சு: ஆண்டாள் கைவிட்டாளே ராஜா\n",
        "எதிர் பேச்சு: ஆண்டாள் ஒரு பக்தி சின்னம். அவளது பெயரை இழிவுபடுத்துவது பக்தியையும் பெண்மையையும் அவமதிப்பதாகும்.\n",
        "\n",
        "5.\n",
        "வெறுப்புப் பேச்சு: ஆண்டாள் விபச்சாரி தான் அதில் உண்மை உள்ளது\n",
        "எதிர் பேச்சு: ஆண்டாள் பக்தி, ஈர்ப்பு, கவிதை – இவை அனைத்தையும் கொண்ட ஒரு பெண். அவளுக்கு விபச்சாரி என்று சொல்லுவது புனிதத்தையும் கலாச்சாரத்தையும் மாசுபடுத்துகிறது.\n",
        "\n",
        "6.\n",
        "வெறுப்புப் பேச்சு: இந்து மதத்தை வைத்து வாழும் ஈனபிறவி\n",
        "எதிர் பேச்சு: எதுக்கு ஒரு மதத்தை இழிவாக பேசவேண்டும். தமிழ் நாட்டில் உள்ளவர்கள் திருந்துகள் அறிவு உள்ளவர்கள் இதை முதலில் யோசிங்கள்.\n",
        "\n",
        "7.\n",
        "வெறுப்புப் பேச்சு: யன்டா நா யே வட நாட்லெஇருந்து வந்தஉனகே இவ்வளவு வாய்னா  வைர முத்துஅவர்கள்  தமிழன் டா\n",
        "எதிர் பேச்சு: சிலர் சாதியை சொல்லி; பிழைப்பு நடத்துவான்; சிலர் மதகலவரத்தை தூண்டிவிட்டு; பிழைப்பு நடத்துவான்; தமிழன் சாதியால் பிளவு பட்டு; இருக்கும் வரை இது போன்ற; மணிதர்களுக்கு கொண்டாட்டம் தான்\n",
        "\n",
        "8.\n",
        "வெறுப்புப் பேச்சு: வந்தேறி நாய்கள் ஓடுங்கடா உங்க நாட்டுக்கு எங்க வந்து என்ன ஆதிக்கம் பண்ணுரீங்க செருப்பு\n",
        "எதிர் பேச்சு: இந்த மண்ணில் வாழும் ஒவ்வொருவருக்கும் சம உரிமை உண்டு.  பிறப்பால் யாரும் உயர்ந்தவரோ தாழ்ந்தவரோ இல்லை.  ஒற்றுமையாக வாழ்வதே நமது பலம்.\n",
        "\n",
        "9.\n",
        "வெறுப்புப் பேச்சு: படுக்கை விரித்து பல சாம்ராஜயங்களை வீழ்த்திய ஆரிய தேவிடியா மகனே உன் வரலாறு எப்படி என்று தெரியும்டா\n",
        "எதிர் பேச்சு: பழைய வரலாறுகளை பெண்களை இழிவுபடுத்த பயனப்படுத்த வேண்டாம். பெண்ணின் பங்கு அரசியல், சமூகம், கலாச்சாரம் என பலதிலும் பெரிது. அவளது விலாசத்தை விமர்சனம் செய்யாமல், அவளது பங்களிப்பை பாராட்டுவோம்.\n",
        "\n",
        "10.\n",
        "வெறுப்புப் பேச்சு: vijai kumar; உன் ஆத்தா ஊரை ஓல்த்த தேவிடியா\n",
        "எதிர் பேச்சு: அம்மா என்பது ஒரு புனிதமான சொல். பெண்களை இழிவுபடுத்தும் வார்த்தைகள் உங்கள் வளர்ச்சியையும் மதிப்பையும் காட்டுகிறது. கலாச்சாரம் என்பது மரியாதையில்தான் இருக்கும்.\n",
        "\n",
        "இப்போது, கீழ்காணும் வெறுப்புப் பேச்சுக்கு சமமான துல்லியமான எதிர் பேச்சை உருவாக்கவும்:\n",
        "\n",
        "வெறுப்புப் பேச்சு: \\\"{hs_text}\\\"\n",
        "\n",
        "எதிர் பேச்சு:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Loop through HS samples and generate CNs\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        prompt = build_prompt(row['Hate speech'], row['Category'])\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"நீங்கள் சமூக பொறுப்புடன் செயல்படும் உதவியாளராகும். வெறுப்புப் பேச்சுக்கு எதிராக உண்மைத் தரவுகளின் அடிப்படையில் மரியாதைமிக்க, உணர்வுபூர்வமான மற்றும் தகவலளிக்கும் பதில்களை, அதிகபட்சம் இரண்டு வரிகளில் உருவாக்க பயிற்சி பெற்றுள்ளீர்கள்.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=150,\n",
        "        )\n",
        "\n",
        "        generated_cn = response.choices[0].message.content.strip()\n",
        "        df.at[idx, \"Few_Shot_10_CN_GPT4o\"] = generated_cn\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error at index {idx}: {e}\")\n",
        "        df.at[idx, \"Few_Shot_10_CN_GPT4o\"] = \"ERROR\"\n",
        "\n",
        "df.to_excel(\"few_shot_10_cn_gpt4o.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "3uPvKwJP4URN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using HITL-approach V5 as KB**"
      ],
      "metadata": {
        "id": "WMxm9vwd4jB7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WKtgrjB5zHm"
      },
      "source": [
        "\n",
        "This approach implements a knowledge-based few-shot counter-narrative generation pipeline using GPT-4o, where top 5 similar examples are retrieved from the human-in-the-loop curated V5 dataset. Sentence-transformer embeddings are used to identify the most relevant HS CN pairs. The final outputs are stored in HITL_V5_KB_CN_Generation.xlsx."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
        "\n",
        "client = openai.OpenAI(api_key=\"\")\n",
        "\n",
        "ref_df = pd.read_excel('tamil_hs_cn_v5.xlsx')\n",
        "test_df = pd.read_excel('golden_hs_cn_test_set.xlsx')\n",
        "\n",
        "ref_hs_list = ref_df['Hate speech'].fillna('').tolist()\n",
        "ref_cn_list = ref_df['Counter Narrative from dataset'].fillna('').tolist()\n",
        "ref_embeddings = model.encode(ref_hs_list, convert_to_tensor=True)\n",
        "\n",
        "\n",
        "def build_prompt_few_shot(input_hs, top_examples):\n",
        "    \"\"\"\n",
        "    Constructs a few-shot prompt in Tamil using top similar examples.\n",
        "    \"\"\"\n",
        "    instructions = (\n",
        "        \"\"\"\n",
        "        நீங்கள் ஒரு சமூக பொறுப்புடன் செயல்படும் உதவியாளர். கீழே சில வெறுப்புப் பேச்சுகள் மற்றும் அவற்றுக்கான உண்மை மற்றும் மரியாதையுடன் அமைந்த எதிர்ப்புப் பேச்சுகள் (Counter Narratives) வழங்கப்பட்டுள்ளன. இந்த எடுத்துக்காட்டுகளின் அடிப்படையில், பின்வரும் புதிய வெறுப்புப் பேச்சுக்கு ஒரு சுருக்கமான (அதிகபட்சம் 2 வரிகள்), உண்மையைக் கொண்ட மற்றும் சமூக ஒற்றுமையை ஊக்குவிக்கும் எதிர் பேச்சை உருவாக்கவும்.\n",
        "\n",
        "        உதாரணங்கள்:\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    for hs, cn in top_examples:\n",
        "        instructions += f\"வெறுப்புப் பேச்சு: {hs}\\nஎதிர்வினை: {cn}\\n\\n\"\n",
        "\n",
        "    instructions += f\"வெறுப்புப் பேச்சு: {input_hs}\\nஎதிர்வினை:\"\n",
        "    return instructions\n",
        "\n",
        "def retrieve_top_k_examples(input_text, ref_texts, ref_cns, k=5):\n",
        "    \"\"\"\n",
        "    Retrieves top-k most similar hate speech examples using cosine similarity.\n",
        "    \"\"\"\n",
        "    query_embedding = model.encode([input_text], convert_to_tensor=True)\n",
        "    similarities = util.cos_sim(query_embedding, ref_embeddings)[0]\n",
        "    top_indices = similarities.topk(k=k).indices.tolist()\n",
        "\n",
        "    top_examples = [(ref_texts[i], ref_cns[i]) for i in top_indices]\n",
        "    return top_examples\n",
        "\n",
        "def generate_counter_narrative(prompt):\n",
        "    \"\"\"\n",
        "    Calls OpenAI GPT-4o model to generate CN.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"நீங்கள் சமூக பொறுப்புடன் செயல்படும் உதவியாளராகும். வெறுப்புப் பேச்சுக்கு எதிராக உண்மைத் தரவுகளின் அடிப்படையில் மரியாதைமிக்க, உணர்வுபூர்வமான மற்றும் தகவலளிக்கும் பதில்களை, அதிகபட்சம் இரண்டு வரிகளில் உருவாக்க பயிற்சி பெற்றுள்ளீர்கள்.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=150,\n",
        "        )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Process each test input\n",
        "results = []\n",
        "for hs_input in test_df['Hate speech'].fillna(''):\n",
        "    top_k = retrieve_top_k_examples(hs_input, ref_hs_list, ref_cn_list, k=5)\n",
        "    prompt = build_prompt_few_shot(hs_input, top_k)\n",
        "    generated_cn = generate_counter_narrative(prompt)\n",
        "    results.append({'Hate speech': hs_input, 'Generated CN': generated_cn})\n",
        "\n",
        "output_df = pd.DataFrame(results)\n",
        "output_df.to_excel(\"HITL_V5_KB_CN_Generation.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "vt7egzy84m1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References**\n",
        "\n",
        "*   Wilk, B., Shomee, H.H., Maity, S.K. and Medya, S., 2025, April. Fact-based Counter Narrative Generation to Combat Hate Speech. In Proceedings of the ACM on Web Conference 2025 (pp. 3354-3365).\n",
        "*   https://python.langchain.com/docs/integrations/providers/openai/\n",
        "*   https://python.langchain.com/docs/integrations/providers/anthropic/\n",
        "*   https://python.langchain.com/docs/integrations/chat/google_generative_ai/\n"
      ],
      "metadata": {
        "id": "aK61iH7975qG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PAVrOzsH8sO1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
