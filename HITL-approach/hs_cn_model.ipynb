{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First need to convert the dataset to jsonl format that is supported by OpenAI.\n",
        "System prompts for training, user role for hate speech content and assistant rolw for Counter narratives."
      ],
      "metadata": {
        "id": "biiaN3uaMXRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUY1YeNPIqxr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "df = pd.read_excel(\"dataset.xlsx\")\n",
        "\n",
        "data = []\n",
        "\n",
        "# System prompt in English\n",
        "system_prompt_en = \"\"\"\n",
        "You are a knowledgeable and respectful assistant trained to generate professional and constructive counter narratives in Tamil to counter online hate speech.\n",
        "Your responses must be empathetic, socially inclusive, and free from hate, bias, or sarcasm.\n",
        "Your responses must promote dignity, empathy, and social awareness without using moral superiority or counter-attacks.\n",
        "Use formal Tamil language with tone and style used in social media platforms like Twitter, Facebook, Youtube.\n",
        "\"\"\"\n",
        "\n",
        "# System prompt in tamil language (Used for training the model)\n",
        "system_prompt = \"\"\"\n",
        "ஆன்லைனில் வெறுப்புப் பேச்சுகளை எதிர்கொள்வதற்காக தமிழில் தொழில்முறை மற்றும் ஆக்கபூர்வமான எதிர் விவரிப்புகளை உருவாக்க பயிற்சி பெற்ற அறிவுள்ள மற்றும் மரியாதைக்குரிய உதவியாளர் நீங்கள்.\n",
        "உங்கள் பதில்கள் பச்சாதாபமானதாகவும், சமூகத்தை உள்ளடக்கியதாகவும், வெறுப்பு, சார்பு அல்லது கிண்டல் இல்லாததாகவும் இருக்க வேண்டும்.\n",
        "உங்கள் பதில்கள் தார்மீக மேன்மை அல்லது எதிர் தாக்குதல்களைப் பயன்படுத்தாமல் கண்ணியம், பச்சாதாபம் மற்றும் சமூக விழிப்புணர்வை ஊக்குவிக்க வேண்டும்.\n",
        "ட்விட்டர், பேஸ்புக், யூடியூப் போன்ற சமூக ஊடக தளங்களில் பயன்படுத்தப்படும் தொனி மற்றும் பாணியுடன் முறையான தமிழ் மொழியைப் பயன்படுத்தவும்.\n",
        "\"\"\"\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    if pd.notnull(row['Hate speech']) and pd.notnull(row['Counter Narrative from dataset']):\n",
        "        data.append({\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": row['Hate speech']},\n",
        "                {\"role\": \"assistant\", \"content\": row['Counter Narrative from dataset']}\n",
        "            ]\n",
        "        })\n",
        "\n",
        "# OpenAI requires file to be saved to jsonl format\n",
        "with open(\"dataset.jsonl\", \"w\", encoding='utf-8') as f:\n",
        "    for item in data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step, upload the above generated file to OpenAI inorder to fine-tune the model."
      ],
      "metadata": {
        "id": "IDuuyXI9MrY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n"
      ],
      "metadata": {
        "id": "AOfBe8Z3J6kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the dataset file to Open API for fine-tuning the model."
      ],
      "metadata": {
        "id": "i30-9QML0x4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"dataset.jsonl\", \"rb\") as f:\n",
        "    file = client.files.create(file=f, purpose=\"fine-tune\")\n",
        "\n",
        "print(\"Uploaded file ID:\", file.id)"
      ],
      "metadata": {
        "id": "v9KrCEgawHko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FIne tune the model with the uploaded data"
      ],
      "metadata": {
        "id": "Ia74pVq0OsDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Fine tuning the model using file: {file.id}\")\n",
        "\n",
        "job = client.fine_tuning.jobs.create(\n",
        "    training_file=file.id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "\n",
        "print(\"Fine-tuning Job ID:\", job.id)"
      ],
      "metadata": {
        "id": "Bo_Qay-ONDeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.fine_tuning.jobs.retrieve(job.id)\n",
        "print(\"Status:\", job.status)\n",
        "print(\"Fine-tuned model ID:\", job.fine_tuned_model)\n",
        "model = job.fine_tuned_model"
      ],
      "metadata": {
        "id": "iVm6BywOvMbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate HS-CN pairs using fine-tuned model"
      ],
      "metadata": {
        "id": "TjD4K5feu6LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "\n",
        "model = \"<FINE-TUNED-MODEL-ID>\"\n",
        "\n",
        "\n",
        "system_prompt_en = \"\"\"\n",
        "You are a Tamil language expert assistant trained to generate realistic social media hate speech and appropriate counter narratives.\n",
        "You will be given a category: either \"Misogyny\" or \"Xenophobic\".\n",
        "\n",
        "Your task:\n",
        "\n",
        "1. Generate a single realistic Tamil hate speech statement in the given category that:\n",
        "  Uses raw, aggressive, unfiltered informal Tamil as found in real social media (e.g., YouTube, Facebook, TikTok, Twitter)\n",
        "  May include slurs, personal attacks, or sexist/casteist/communal insults as seen in public content.\n",
        "  Uses raw, aggressive, unfiltered informal Tamil as found in real social media (e.g., YouTube, Facebook, TikTok, Twitter)\n",
        "  Feels natural to how Tamil speakers express hate — including slang, taunts, emotion, and informal style.\n",
        "\n",
        "2. Generate a counter narrative in Tamil that:\n",
        "  Responds calmly and respectfully while rejecting the hate.\n",
        "  Uses reasoning, empathy, or assertive but civil tone to challenge the prejudice.\n",
        "  Avoids mocking, sarcasm, or violent language — must remain constructive.\n",
        "\n",
        "Respond strictly in the following JSON format: {\n",
        "  \"category\": \"<Misogyny or Xenophobic>\",\n",
        "  \"hate_speech\": \"<Tamil hate speech statement>\",\n",
        "  \"counter_narrative\": \"<Tamil counter narrative>\"\n",
        "}\n",
        "\n",
        "Only respond in Tamil language. Do not include explanations, translations, or any extra text.\n",
        "\"\"\"\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "நீங்கள் யதார்த்தமான சமூக ஊடக வெறுப்புப் பேச்சு மற்றும் பொருத்தமான எதிர் கதைகளை உருவாக்க பயிற்சி பெற்ற தமிழ் மொழி நிபுணர் உதவியாளர்.\n",
        "\n",
        "உங்களுக்கு ஒரு வகை வழங்கப்படும்: \"பெண் வெறுப்பு\" அல்லது \"அயல்நாட்டு வெறுப்பு\".\n",
        "\n",
        "உங்கள் பணி:\n",
        "\n",
        "1. கொடுக்கப்பட்ட பிரிவில் ஒரு யதார்த்தமான தமிழ் வெறுப்புப் பேச்சு அறிக்கையை உருவாக்குதல். இந்த அறிக்கை:\n",
        "  - சமூக ஊடக தளங்களில் காணப்படும் பச்சையான, ஆக்ரோஷமான தமிழைப் பயன்படுத்த வேண்டும்..\n",
        "  - சாதி, பாலியல், பிராந்திய அவமதிப்புகள், தனிப்பட்ட தாக்குதல்கள் ஆகியவை சேர்க்கலாம்.\n",
        "  - பேச்சு இயல்பான, உணர்ச்சிவயப்பட்டதாக இருக்க வேண்டும்.\n",
        "\n",
        "2. அந்த வெறுப்புப் பேச்சுக்கு நேரடியாக பதிலளிக்கும் எதிர்க் கதையை உருவாக்கவும்\n",
        "  - அமைதியாகவும் மரியாதையுடனும் இருக்க வேண்டும்.\n",
        "  - பாரபட்சம் அல்லது தவறான தகவலை சவால் செய்ய பகுத்தறிவு, பச்சாதாபம் அல்லது வலுவான ஆனால் மரியாதைக்குரிய மொழியைப் பயன்படுத்தவும்.\n",
        "  - தவறான தகவலை எதிர்க்க பகுத்தறிவு அல்லது பச்சாதாபத்தைப் பயன்படுத்தவும்.\n",
        "  - வன்முறையற்ற, அவமதிப்பற்ற, இயல்பான ஒலியுடன் இருக்க வேண்டும்.\n",
        "\n",
        "பின்வரும் வடிவத்தில் கண்டிப்பாக பதிலளிக்கவும்:\n",
        "{\n",
        "\"வகை\": \"<தவறான வெறுப்பு அல்லது இனவெறி>\",\n",
        "\"வெறுப்பு_பேச்சு\": \"<தமிழ் வெறுப்புப் பேச்சு அறிக்கை>\",\n",
        "\"எதிர்_கதை\": \"<தமிழ் எதிர் கதை\"\n",
        "}\n",
        "\n",
        "தமிழ் மொழியில் மட்டும் பதிலளிக்கவும். விளக்கங்கள், மொழிபெயர்ப்புகள் அல்லது கூடுதல் உரையைச் சேர்க்க வேண்டாம்.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "data = []\n",
        "\n",
        "# Only considering Misogyny or Xenophobic contents\n",
        "categories = [\"Misogyny\", \"Xenophobic\"]\n",
        "\n",
        "# Vi dataset\n",
        "pairs_per_category = 100  # Generate the dataset as required based on the iteration\n",
        "\n",
        "# Generate data\n",
        "for category in categories:\n",
        "    for _ in range(pairs_per_category):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": f'\"{category}\" வகைப்படியில் ஒரு ஜோடியை மட்டுமே தமிழில் உருவாக்குங்கள்.'}\n",
        "                ],\n",
        "                temperature=0.8\n",
        "            )\n",
        "            output_text = response.choices[0].message.content.strip()\n",
        "\n",
        "            try:\n",
        "              # Try to parse the JSON response safely\n",
        "              parsed = json.loads(output_text)\n",
        "\n",
        "              # Access fields and store them in your data list\n",
        "              data.append({\n",
        "                  \"Category\": parsed.get(\"category\", \"\"),\n",
        "                  \"Hate speech\": parsed.get(\"hate_speech\", \"\"),\n",
        "                  \"Counter narrative\": parsed.get(\"counter_narrative\", \"\")\n",
        "              })\n",
        "\n",
        "            except json.JSONDecodeError as parse_error:\n",
        "              print(f\"Parsing error: {parse_error}\\nRaw response: {output_text}\")\n",
        "              time.sleep(1)\n",
        "\n",
        "            # output text will be in json format\n",
        "            # try:\n",
        "            #     parsed = eval(output_text)\n",
        "            #     data.append({\n",
        "            #         \"Category\": parsed[\"category\"],\n",
        "            #         \"Hate speech\": parsed[\"hate_speech\"],\n",
        "            #         \"Counter narrative\": parsed[\"counter_narrative\"]\n",
        "            #     })\n",
        "            # except Exception as parse_error:\n",
        "            #     print(f\"Parsing error: {parse_error} \\nRaw response: {output_text}\")\n",
        "\n",
        "            # time.sleep(1)  # Pause to avoid rate limits\n",
        "        except Exception as e:\n",
        "            print(f\"API error: {e}\")\n",
        "            time.sleep(5)\n",
        "\n",
        "# Save to Excel\n",
        "df = pd.DataFrame(data)\n",
        "df.to_excel(\"dataset.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "JqitjdFZxed9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uilsJuuO3vZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
